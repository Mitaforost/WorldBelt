# –∏—â–µ—Ç –≤—Å–µ —Ç–æ–≤–∞—Ä—ã –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Å—Ç–æ–∏—Ç –≤ –±–ª–æ–∫–µ –æ–ø–∏—Å–∞–Ω–∏—è (–ø—Ä–æ–ø—É—â–µ–Ω–∞ —ç—Ç–∞ —á–µ—Ä—Ç–æ—á–∫–∞)

from selenium import webdriver
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time

def extract_articuls_with_wrong_more(start_url):
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    driver = webdriver.Chrome(options=options)

    unique_articuls = set()  # –î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤

    try:
        print(f"üîç –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É: {start_url}")
        driver.get(start_url)
        time.sleep(2)

        # –ù–∞–∂–∏–º–∞–µ–º "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë", –ø–æ–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–∞
        while True:
            try:
                show_more = driver.find_element(By.XPATH, '//button[@radicalmart-ajax-paginaton="button"]')
                driver.execute_script("arguments[0].click();", show_more)
                time.sleep(1)
            except:
                break

        soup = BeautifulSoup(driver.page_source, 'html.parser')
        product_links = [a['href'] for a in soup.select('a.h6.text-decoration-none') if a.get('href')]
        print(f"üîó –ù–∞–π–¥–µ–Ω–æ {len(product_links)} —Ç–æ–≤–∞—Ä–æ–≤.")

        for i, link in enumerate(product_links, 1):
            full_url = urljoin(start_url, link)
            print(f"\nüõí [{i}/{len(product_links)}] –ü—Ä–æ–≤–µ—Ä–∫–∞: {full_url}")

            try:
                driver.get(full_url)
                time.sleep(1)
                product_soup = BeautifulSoup(driver.page_source, 'html.parser')

                # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –±–ª–æ–∫–∏ col-md-4
                col_md_4_blocks = product_soup.find_all('div', class_='col-md-4')
                
                found_wrong = False
                
                for col_md_4 in col_md_4_blocks:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞–∫–∫–æ—Ä–¥–µ–æ–Ω–∞ –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—É—â–µ–≥–æ col-md-4
                    if col_md_4.find('div', id='rlta-podrobnee'):
                        print("‚ùóÔ∏è –ù–∞–π–¥–µ–Ω —Ç–æ–≤–∞—Ä —Å –∞–∫–∫–æ—Ä–¥–µ–æ–Ω–æ–º –≤ col-md-4")
                        found_wrong = True
                        break
                
                if not found_wrong:
                    print("‚úÖ –ê–∫–∫–æ—Ä–¥–µ–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ col-md-4 ‚Äî —Ç–æ–≤–∞—Ä –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π")
                    continue

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ä—Ç–∏–∫—É–ª –∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
                articul = None
                characteristics = product_soup.find('dl', class_='product-main-fields')
                if characteristics:
                    for dt in characteristics.find_all('dt'):
                        if '–ê—Ä—Ç–∏–∫—É–ª' in dt.get_text(strip=True):
                            dd = dt.find_next_sibling('dd')
                            if dd:
                                articul = dd.get_text(strip=True)
                                break

                if articul:
                    if articul not in unique_articuls:
                        unique_articuls.add(articul)
                        print(f"üìå –ù–∞–π–¥–µ–Ω –Ω–æ–≤—ã–π –∞—Ä—Ç–∏–∫—É–ª: {articul}")
                    else:
                        print(f"‚ÑπÔ∏è –ê—Ä—Ç–∏–∫—É–ª {articul} —É–∂–µ –±—ã–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Ä–∞–Ω–µ–µ")
                else:
                    print("‚ö†Ô∏è –ê—Ä—Ç–∏–∫—É–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–æ–≤–∞—Ä–∞: {e}")
                continue

    finally:
        driver.quit()

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã –≤ —Ñ–∞–π–ª
    if unique_articuls:
        with open("articuls.txt", "w", encoding="utf-8") as out_file:
            out_file.write("\n".join(sorted(unique_articuls)))
        print(f"\nüìÅ –ì–æ—Ç–æ–≤–æ! –ù–∞–π–¥–µ–Ω–æ –∏ –∑–∞–ø–∏—Å–∞–Ω–æ {len(unique_articuls)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –≤ 'articuls.txt'")
    else:
        print("\nüìÅ –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ —Å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ–º –∞–∫–∫–æ—Ä–¥–µ–æ–Ω–∞")

# –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    url = input("–í–≤–µ–¥–∏—Ç–µ URL –∫–∞—Ç–∞–ª–æ–≥–∞: ").strip()
    extract_articuls_with_wrong_more(url)