"""
üåê –ü–∞—Ä—Å–µ—Ä –°—Ç—Ä–∞–Ω–∏—Ü —Å –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –ü–æ–¥–≥—Ä—É–∑–∫–æ–π (Selenium + BeautifulSoup)

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü —Å–∞–π—Ç–∞, –≥–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–Ω–æ–ø–∫–∞ "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë"
(–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –ø–æ–¥–≥—Ä—É–∑–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤), –∞ –∑–∞—Ç–µ–º –∏–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∞–∑–¥–µ–ª–æ–≤.

üß† –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
- Selenium (—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –±—Ä–∞—É–∑–µ—Ä–æ–º, –∫–ª–∏–∫ –ø–æ –∫–Ω–æ–ø–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏)
- BeautifulSoup (–ø–∞—Ä—Å–∏–Ω–≥ HTML)
- Headless Chrome (—Ä–∞–±–æ—Ç–∞ –±–µ–∑ GUI)

üìÑ –ß—Ç–æ –¥–µ–ª–∞–µ—Ç:
1. –ü–µ—Ä–µ—Ö–æ–¥–∏—Ç –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π URL
2. –ù–∞–∂–∏–º–∞–µ—Ç –∫–Ω–æ–ø–∫—É "–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë", –ø–æ–∫–∞ –æ–Ω–∞ –¥–æ—Å—Ç—É–ø–Ω–∞
3. –ò–∑–≤–ª–µ–∫–∞–µ—Ç:
   - –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (`<h1>`)
   - –°—Å—ã–ª–∫–∏/–Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤ (—Å–µ–ª–µ–∫—Ç–æ—Ä: `a.h6.text-decoration-none`)
4. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ:
   - `structure.txt` ‚Äî —Å–ø–∏—Å–æ–∫ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
   - `output.txt` ‚Äî –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏

üì¶ –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
    pip install selenium beautifulsoup4

üîß –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:
- –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ChromeDriver –∏ –æ–Ω –¥–æ–±–∞–≤–ª–µ–Ω –≤ PATH
- –†–∞–±–æ—Ç–∞–µ—Ç –≤ headless-—Ä–µ–∂–∏–º–µ (–±–µ–∑ –æ—Ç–∫—Ä—ã—Ç–∏—è –æ–∫–Ω–∞ –±—Ä–∞—É–∑–µ—Ä–∞)

"""
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup
import time

def extract_text_and_structure(url, structure_file="structure.txt", output_file="output.txt"):
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")  # –ó–∞–ø—É—Å–∫ –±–µ–∑ GUI
    driver = webdriver.Chrome(options=options)

    try:
        driver.get(url)
        time.sleep(2)

        click_count = 0
        while True:
            try:
                button = driver.find_element(By.XPATH, '//button[@radicalmart-ajax-paginaton="button"]')
                driver.execute_script("arguments[0].click();", button)
                time.sleep(2)  # –ñ–¥—ë–º –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                click_count += 1
            except:
                print("–ö–Ω–æ–ø–∫–∞ '–ü–æ–∫–∞–∑–∞—Ç—å –µ—â—ë' –±–æ–ª—å—à–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
                break

        print(f"–ö–Ω–æ–ø–∫–∞ –±—ã–ª–∞ –Ω–∞–∂–∞—Ç–∞ {click_count} —Ä–∞–∑.")

        # –ü–æ–ª—É—á–∞–µ–º HTML-–∫–æ–¥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–¥–≥—Ä—É–∑–æ–∫
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        h1_tag = soup.find('h1')
        page_title = h1_tag.text.strip() if h1_tag else "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        with open(structure_file, "a", encoding="utf-8") as f:
            f.write(f"- {page_title}\n")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–≤–∞—Ä—ã
        product_cards = soup.select('div.row.row-cols-2.row-cols-md-2.row-cols-lg-3 a.h6.text-decoration-none')
        products = {card.text.strip() for card in product_cards}

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —Ñ–∞–π–ª
        with open(output_file, "a", encoding="utf-8") as f:
            f.write(f"{'=' * 50}\n{page_title}\n\n")
            f.write("\n".join(products) + "\n" if products else "–¢–æ–≤–∞—Ä—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç\n")
            f.write(f"{'=' * 50}\n\n")

        print(f"–ù–∞–π–¥–µ–Ω–æ {len(products)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤.")
        print("–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω!")

    finally:
        driver.quit()

if __name__ == "__main__":
    start_url = input("–í–≤–µ–¥–∏—Ç–µ URL —Å–∞–π—Ç–∞: ").strip()

    # –û—á–∏—â–∞–µ–º —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º
    open("structure.txt", "w", encoding="utf-8").close()
    open("output.txt", "w", encoding="utf-8").close()

    extract_text_and_structure(start_url)
    print("–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω!")
